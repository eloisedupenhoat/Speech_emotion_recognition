{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e7d5414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from google.cloud import storage\n",
    "import librosa as li\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b2d6e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the google cloud storage bucket we will be working on\n",
    "BUCKET_NAME = \"speech-emotion-bucket\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8747e771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the folder inside the bucket we will be working on\n",
    "PREFIX = \"Raw/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fa5bd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a client object to interact with GCS\n",
    "# loggin in into our GCS environment\n",
    "client = storage.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd279fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the list of files (blobs) inside the bucket\n",
    "# stores those files into a variable blobs\n",
    "blobs = client.list_blobs(BUCKET_NAME, prefix=PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81ad6e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterates trough each file inside the bucket\n",
    "for blob in blobs:\n",
    "    if blob.name.endswith(\".wav\"):\n",
    "\n",
    "        # downloads each audio file and stores it into a binary data variable\n",
    "        bytes_data = blob.download_as_bytes(raw_download=True)\n",
    "        binary_data = BytesIO(bytes_data)\n",
    "\n",
    "        # load the audio into librosa\n",
    "\t    # y is a NumPy array witht he waveform data\n",
    "        # sr is the sample rate (16khz)\n",
    "        y, sr = li.load(binary_data, sr=None)\n",
    "\n",
    "        # scales the waveform so the maximum value is 1\n",
    "        y = y / np.abs(y).max()\n",
    "\n",
    "        # remove silence\n",
    "        # silence is defined by a decibel threshold (tob_db)\n",
    "        # default should be around 60 db\n",
    "        y, _ = li.effects.trim(y)\n",
    "\n",
    "        # compute the mel spectogram\n",
    "        # it's a 2d array (rows = frequency ; columns = time ; values = intensity (brightness))\n",
    "        S = li.feature.melspectrogram(y=y, sr=sr)\n",
    "\n",
    "        # convert the spectogram from raw energy (power) into decibel scale (log scale)\n",
    "        S_dB = li.power_to_db(S, ref=np.max)\n",
    "\n",
    "        # convert the standardized spectogram into an image file & save it in the cloud\n",
    "\n",
    "        # create matlotplib figute size with 64 pixels\n",
    "        fig = plt.figure(figsize=(4, 4), dpi=100)\n",
    "\n",
    "        # display image (lower flips the image so that it's well represented)\n",
    "        plt.imshow(S_dB, cmap=\"magma\", origin=\"lower\", aspect=\"auto\")\n",
    "        # remove axis\n",
    "        plt.axis(\"off\")\n",
    "        # create temporary memory\n",
    "        buf = BytesIO()\n",
    "        # saves image (no padding, resolution = 100)\n",
    "        plt.savefig(buf, format=\"jpg\", bbox_inches=\"tight\", pad_inches=0, dpi=100)\n",
    "        # close figure to free memory\n",
    "        plt.close()\n",
    "        # we need this I don't know why\n",
    "        buf.seek(0)\n",
    "\n",
    "        # Resize image to 64x64 in RGB & using the LANCZOS algorithm\n",
    "        image = Image.open(buf).convert(\"RGB\")\n",
    "        image = image.resize((64, 64), resample=Image.Resampling.LANCZOS)\n",
    "\n",
    "        # Save back to buffer for cloud upload\n",
    "        resized_buf = BytesIO()\n",
    "        image.save(resized_buf, format=\"JPEG\")  # Quality tweakable\n",
    "        resized_buf.seek(0)\n",
    "\n",
    "        # Define the destination (the place where I'll save it: in the bucket)\n",
    "        # Save the spectogram images into a new folder (Spectograms)\n",
    "        output_path = blob.name.replace(\"Raw/\", \"Spectrograms_64_p/\")\n",
    "        # Change the files from audio to images\n",
    "        output_path = output_path.replace(\".wav\", \".jpg\")\n",
    "        # Get the bucket where we want to store our data\n",
    "        bucket = client.bucket(BUCKET_NAME)\n",
    "        # Create a new blob (a new file) for each image\n",
    "        image_blob = bucket.blob(output_path)\n",
    "        # Upload the image in each blob (in the cloud), specify that it's an image\n",
    "        image_blob.upload_from_file(resized_buf, content_type=\"image/jpeg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech_emotion_recognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
