# ğŸ¤ Speech Emotion Recognition

Projet de prÃ©diction des Ã©motions humaines Ã  partir de la voix.  
RÃ©alisÃ© dans le cadre dâ€™une formation IA / Data Science.

---

## ğŸ§  Objectif du projet

L'objectif est de dÃ©tecter lâ€™Ã©motion exprimÃ©e par un locuteur Ã  partir dâ€™un enregistrement audio.  
Le pipeline inclut : prÃ©traitement, extraction de features audio, modÃ©lisation, interface Streamlit.

---

## ğŸš€ FonctionnalitÃ©s

- ğŸ”Š Extraction automatique des caractÃ©ristiques audio (MFCC, spectrogrammes, etc.)
- ğŸ§ª ModÃ¨les entraÃ®nÃ©s avec Keras & PyTorch (classification)
- ğŸ“Š Analyse de performance des modÃ¨les
- ğŸ–¥ï¸ Interface utilisateur via Streamlit pour tester une prÃ©diction en live
- ğŸ³ IntÃ©gration Docker pour dÃ©ploiement reproductible

---

## ğŸ› ï¸ Stack technique

- **Langages** : Python
- **Librairies principales** :
  - Audio : `librosa`, `soundfile`
  - Machine learning : `scikit-learn`, `keras`, `torch`
  - Interface : `streamlit`
  - Utilitaires : `numpy`, `pandas`, `matplotlib`, `seaborn`


---


## ğŸ“¦ Installation

Cloner le repo et installer les dÃ©pendances :

`git clone https://github.com/ton-user/Speech_emotion_recognition.git` 
`cd Speech_emotion_recognition`
`pip install -r requirements.txt`

_ _  _

## ğŸ“ Structure du projet


`.`
`â”œâ”€â”€ D1_modules/         # Traitement, extraction de features, modÃ¨les`
`â”œâ”€â”€ D2_interface/       # Interface utilisateur (Streamlit)`
`â”œâ”€â”€ hooks/              # Pre-commit et outils dev`
`â”œâ”€â”€ params.py           # ParamÃ¨tres globaux du projet`
`â”œâ”€â”€ requirements.txt    # DÃ©pendances pour dev`
`â”œâ”€â”€ requirements_prod.txt`
`â”œâ”€â”€ Dockerfile          # Image Docker pour dÃ©ploiement`
`â”€â”€ install-hooks.sh    # Script pour activer les hooks Git`
`â””â”€â”€ README.md           # Ce fichier`



## ğŸ‘¥ Auteurs

Projet rÃ©alisÃ© par :

eloisedupenhoat

gaspardasilveira

Chrisgrd

FRmathieu13


## ğŸ“„ Licence
Ce projet est sous licence MIT.




